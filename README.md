# Collection-of-Underwater-Object-Detection-Dataset
This is a collection of underwater object detection dataset.



### UTDAC2020

**Introduction**

Four classes: echinus, holothurian, scallop, starfish



**Download**

https://github.com/mousecpn/Boosting-R-CNN-Reweighting-R-CNN-Samples-by-RPN-s-Error-for-Underwater-Object-Detection

![image](https://user-images.githubusercontent.com/46233799/179469007-20f0bbc0-514b-40b6-bbe8-ef1b7a6e0ce1.png)


### UODD

**Introduction**

Paper: [Underwater Species Detection using Channel Sharpening Attention](https://www.researchgate.net/profile/Xin-Fan-2/publication/355375809_Underwater_Species_Detection_using_Channel_Sharpening_Attention/links/617b4f650be8ec17a9424b49/Underwater-Species-Detection-using-Channel-Sharpening-Attention.pdf)

Four classes: sea cucumber, sea urchin, scallop

**Download**

https://github.com/LehiChiang/Underwater-object-detection-dataset


### DUO

**Introduction**

Underwater object detection for robot picking has attracted a lot of interest. However, it is still an unsolved problem due to several challenges. We take steps towards making it more realistic by addressing the following challenges. Firstly, the currently available datasets basically lack the test set annotations, causing researchers must compare their method with other SOTAs on a self-divided test set (from the training set). Training other methods lead to an increase in workload and different researchers divide different datasets, resulting there is no unified benchmark to compare the performance of different algorithms. Secondly, these datasets also have other shortcomings, e.g., too many similar images or incomplete labels. Towards these challenges we introduce a dataset, Detecting Underwater Objects (DUO), and a corresponding benchmark, based on the collection and re-annotation of all relevant datasets. DUO contains a collection of diverse underwater images with more rational annotations. The corresponding benchmark provides indicators of both efficiency and accuracy of SOTAs (under the MMDtection framework) for academic research and industrial applications, where JETSON AGX XAVIER is used to assess detector speed to simulate the robot-embedded environment.


**Download**

https://github.com/chongweiliu/DUO


### Trashcan

**Introduction**

Paper: [TrashCan 1.0 An Instance-Segmentation Labeled Dataset of Trash Observations](https://arxiv.org/abs/2007.08097) 

Including two datasets: trashcan_material, trashcan_instance

![image](https://user-images.githubusercontent.com/46233799/179469571-5a6089a2-2b81-479f-915f-4d97c2946bde.png)

![image](https://user-images.githubusercontent.com/46233799/179469460-d93f1aa0-7be3-452a-884f-9ee444015c03.png)


**Download**

https://conservancy.umn.edu/handle/11299/214865



### Brackish

**Introduction**

Paper: [Detection of marine animals in a new underwater dataset with varying visibility](http://openaccess.thecvf.com/content_CVPRW_2019/papers/AAMVEM/Pedersen_Detection_of_Marine_Animals_in_a_New_Underwater_Dataset_with_CVPRW_2019_paper.pdf)

Six classes: Big fish, Crab, Jellyfish, Shrimp, Small fish, Starfish

![image](https://user-images.githubusercontent.com/46233799/179469045-4a539146-0a5e-4ce0-929a-3ddb86c15c6e.png)


**Download**

https://www.kaggle.com/datasets/aalborguniversity/brackish-dataset



### S-URPC2019

**Introduction**

Paper: [TOWARDS DOMAIN GENERALIZATION IN UNDERWATER OBJECT DETECTION](https://arxiv.org/abs/2004.06333)

Four classes: echinus, holothurian, scallop, starfish, waterweed

**Download**

https://github.com/mousecpn/DG-YOLO



### S-UODAC2020

**Introduction**

Paper: [Achieving Domain Generalization in Underwater Object Detection by Domain Mixup and Contrastive Learning](https://arxiv.org/abs/2104.02230)

Four classes: echinus, holothurian, scallop, starfish

**Download**

https://github.com/mousecpn/DMC-Domain-Generalization-for-Underwater-Object-Detection

<img width="447" alt="image" src="https://github.com/user-attachments/assets/d5c7fbb0-0b30-498b-9f14-fb19636cf119">


### FishDet

**Download**

https://github.com/mDp0r/FishDet

### WPBB

**Introduction**

Paper: [Towards More Efficient EfficientDets and Real-Time Marine Debris Detection](https://ieeexplore.ieee.org/document/10044917)

WPBB is a detection dataset of in-water plastic bags and bottles, which is comprised of annotated images (900 images currently). It contains 2 common categories: plastic bags and plastic bottles. The training set and test set are randomly split into 720 and 180, respectively.

![image](https://github.com/mousecpn/Collection-of-Underwater-Object-Detection-Dataset/assets/46233799/7e3c4d82-baff-4d68-b6ba-4c9db05e9bf1)


**Download**

https://github.com/fedezocco/MoreEffEffDetsAndWPBB-TensorFlow

### DeepFish

**Introduction**

[A realistic fish-habitat dataset to evaluate algorithms for underwater visual analysis
](https://www.nature.com/articles/s41598-020-71639-x)

The dataset consists of approximately 40 thousand images collected underwater from 20 habitats in the marine-environments of tropical Australia. The dataset originally contained only classification labels. Thus, we collected point-level and segmentation labels to have a more comprehensive fish analysis benchmark. Videos for DeepFish were collected for 20 habitats from remote coastal marine environments of tropical Australia. These videos were acquired using cameras mounted on metal frames, deployed over the side of a vessel to acquire video footage underwater. The cameras were lowered to the seabed and left to record the natural fish community, while the vessel maintained a distance of 100 m. The depth and the map coordinates of the cameras were collected using an acoustic depth sounder and a GPS, respectively. Video recording was carried out during daylight hours and in relatively low turbidity periods. The video clips were captured in full HD resolution (1920 Ã— 1080 pixels) from a digital camera. In total, the number of video frames taken is 39,766.

![image](https://github.com/mousecpn/Collection-of-Underwater-Object-Detection-Dataset/assets/46233799/28e3bb2d-f50f-4a06-bcda-c6928213e463)

**Download**

https://github.com/alzayats/DeepFish.git

### SUIM dataset

**Introduction**

[Semantic Segmentation of Underwater Imagery: Dataset and Benchmark](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9340821)

This paper presents the first large-scale dataset for semantic Segmentation of Underwater IMagery (SUIM). It contains over 1500 images with pixel annotations for eight object categories: fish (vertebrates), reefs (invertebrates), aquatic plants, wrecks/ruins, human divers, robots, and sea-floor. The images are rigorously collected during oceanic explorations and human-robot collaborative experiments, and annotated by human participants.

![image](https://github.com/user-attachments/assets/55afccf0-06cb-43a6-a209-bf13c9a02ac1)


**Download**

https://irvlab.cs.umn.edu/image-segmentation/suim
